{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajitonelsonn/TELE_Feedback/blob/main/Llama_Chatbot_with_Sentiment_Analysis_Integration_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TELE Feedback**\n",
        "\n",
        "TELE Feedback is an AI-powered chatbot designed for a telecommunications company in Timor-Leste. It allows customers to provide feedback while integrating sentiment analysis to assess the tone of their messages. The project includes a simple interface for interaction and visualization of sentiment trends."
      ],
      "metadata": {
        "id": "ff9PKaHr1vj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.**Installing Required Libraries**\n",
        "\n",
        "This cell installs all the libraries that the project depends on. These libraries are necessary for different functionalities like interacting with the Hugging Face models, creating a web interface for the chatbot, handling database operations, and visualizing feedback data.\n",
        "\n",
        "- **`huggingface_hub`**: Allows the project to access pre-trained models from Hugging Face's model hub.\n",
        "- **`gradio`**: Used to create an interactive web interface for the chatbot where users can input text and get responses.\n",
        "- **`transformers`**: A library from Hugging Face that provides tools to use pre-trained models for natural language processing tasks, like language generation and sentiment analysis.\n",
        "- **`sqlalchemy`**: An SQL toolkit for Python that helps in managing the storage and retrieval of data in a database.\n",
        "- **`pandas`**: Used for data manipulation and analysis.\n",
        "- **`matplotlib`**: A popular plotting library used for visualizing data, such as feedback trends.\n",
        "- **`torch`**: PyTorch is a framework used for loading and running machine learning models."
      ],
      "metadata": {
        "id": "LbTx0nin4AGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsivCpEll_Ig"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub gradio git+https://github.com/huggingface/transformers sqlalchemy pandas matplotlib torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.**Importing Necessary Libraries**\n",
        "\n",
        "This cell imports all the necessary libraries and modules required throughout the project.\n",
        "\n",
        "- **`huggingface_hub.login`**: Used to log in to Hugging Face, so you can access models stored in your account or publicly available models.\n",
        "- **`gradio`**: Used for creating a user interface where people can interact with your chatbot.\n",
        "- **`transformers.AutoModelForCausalLM` and `AutoTokenizer`**: These two classes load a pre-trained language model and its tokenizer, which are essential for generating chatbot responses.\n",
        "- **SQLAlchemy-related imports**:\n",
        "  - **`create_engine`**: Connects the code to the SQLite database.\n",
        "  - **`Column`, `Integer`, `String`**: These are data types used to define the database schema.\n",
        "  - **`declarative_base`**: A base class used to define the database table structure.\n",
        "  - **`sessionmaker`**: Creates sessions to interact with the database.\n",
        "- **`torch`**: PyTorch framework, required to load and run machine learning models like the chatbot.\n",
        "- **`matplotlib.pyplot`**: This is used to plot graphs or charts, such as visualizing feedback data trends.\n",
        "- **`collections.Counter`**: This utility helps in counting the occurrences of feedback sentiments (positive, negative, neutral)."
      ],
      "metadata": {
        "id": "NBJjzFuM4Lnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG6vgKlwd1Fi"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sqlalchemy import create_engine, Column, Integer, String\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.**Hugging Face Login**\n",
        "\n",
        "This cell is responsible for logging into Hugging Face using your personal API token. If you don’t log in, you won’t be able to access models that are either private or require authentication.\n",
        "\n",
        "- **`login(token=\"your_huggingface_token_here\")`**: Replace `\"your_huggingface_token_here\"` with your actual token from Hugging Face. This allows the script to access models and datasets from the Hugging Face platform."
      ],
      "metadata": {
        "id": "sE8_y9Ke4e2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc4IIR8Sd2xL"
      },
      "outputs": [],
      "source": [
        "# Hugging Face login (you need to provide your token)\n",
        "login(token=\"your_huggingface_token_here\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4.**Loading the Pre-Trained Model and Tokenizer**\n",
        "\n",
        "This cell loads the language model and tokenizer that will be used to generate chatbot responses.\n",
        "\n",
        "- **`AutoTokenizer.from_pretrained(\"model_name\")`**: This loads a tokenizer from Hugging Face. The tokenizer processes raw text input and converts it into tokens that the model can understand.\n",
        "- **`AutoModelForCausalLM.from_pretrained(\"model_name\")`**: This loads the pre-trained language model. A causal language model (like GPT) is capable of generating text responses based on the input tokens.\n",
        "\n",
        "The `model_name` should be replaced with the actual name of the pre-trained model you are using (for example, \"gpt-3\", \"gpt-2\", etc.). In this project we use **NousResearch/Llama-2-7b-chat-hf**"
      ],
      "metadata": {
        "id": "KMPEd83J4_CV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir35KJLOd_zD"
      },
      "outputs": [],
      "source": [
        "# Load Llama 2 model\n",
        "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.**Database Setup**\n",
        "\n",
        "This code sets up a database for the project using SQLAlchemy's ORM.\n",
        "\n",
        "- **`Base = declarative_base()`**: This creates a base class for all the declarative models.\n",
        "- **`engine = create_engine('sqlite:///telecom_support.db', echo=False)`**: This creates a SQLite database named `telecom_support.db` and an engine to communicate with it.\n",
        "  - **`echo=False`**: Suppresses SQLAlchemy log output.\n",
        "- **`Session = sessionmaker(bind=engine)`**: Creates a session factory, which allows you to interact with the database.\n",
        "- **`class Feedback(Base)`**: Defines a class `Feedback` that represents a table in the database.\n",
        "  - **`__tablename__ = 'feedback'`**: The name of the table in the database.\n",
        "  - **`id = Column(Integer, primary_key=True)`**: The primary key column for the feedback records.\n",
        "  - **`category = Column(String)`**: Stores the category of the feedback.\n",
        "  - **`original_text = Column(String)`**: Stores the original text of the feedback.\n",
        "  - **`sentiment = Column(String)`**: Stores the sentiment of the feedback (e.g., positive or negative).\n",
        "  - **`response = Column(String)`**: Stores the generated response for the feedback.\n",
        "- **`Base.metadata.create_all(engine)`**: This line creates the tables in the database if they don't already exist."
      ],
      "metadata": {
        "id": "KcCQKmPf-SdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ4HbQDyd4QF"
      },
      "outputs": [],
      "source": [
        "# Database setup\n",
        "Base = declarative_base()\n",
        "engine = create_engine('sqlite:///telecom_support.db', echo=False)\n",
        "Session = sessionmaker(bind=engine)\n",
        "\n",
        "class Feedback(Base):\n",
        "    __tablename__ = 'feedback'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    category = Column(String)\n",
        "    original_text = Column(String)\n",
        "    sentiment = Column(String)\n",
        "    response = Column(String)\n",
        "\n",
        "Base.metadata.create_all(engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.**Updated Categories for a Telecom Company**\n",
        "\n",
        "This code defines a list of categories for a telecom company. Each category represents a specific area of service or product offering.\n",
        "\n",
        "- **`Mobile Network`**: Refers to issues or feedback related to the telecom company's mobile network services, such as signal strength or coverage.\n",
        "- **`Mobile Package`**: Deals with feedback about mobile plans or packages, such as data, call minutes, or SMS bundles.\n",
        "- **`Mosan Emoney`**: Refers to feedback concerning the telecom's electronic money services or mobile wallet.\n",
        "- **`Recharge`**: Encompasses issues or feedback related to recharging mobile credit or data balances."
      ],
      "metadata": {
        "id": "LuziOib__Dd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPxNmYMaeBUJ"
      },
      "outputs": [],
      "source": [
        "# Updated categories for a telecom company\n",
        "CATEGORIES = [\"Mobile Network\", \"Mobile Package\", \"Mosan Emoney\", \"Recharge\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.**Response Generation Function**\n",
        "\n",
        "This function generates a response based on the given prompt using a pre-trained language model.\n",
        "\n",
        "- **`prompt`**: The input text or prompt for which a response is generated.\n",
        "- **`max_length=500`**: Sets the maximum length of the generated response (default is 500 tokens).\n",
        "- **`inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)`**:\n",
        "  - **`tokenizer`**: Converts the prompt into tokenized tensor format.\n",
        "  - **`return_tensors=\"pt\"`**: Converts the input into PyTorch tensor format.\n",
        "  - **`.to(model.device)`**: Moves the input to the device (CPU/GPU) where the model is loaded.\n",
        "- **`outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1, temperature=0.7)`**:\n",
        "  - **`model.generate()`**: Generates the response based on the input tokens.\n",
        "  - **`max_length`**: Limits the length of the generated output.\n",
        "  - **`num_return_sequences=1`**: Returns one generated response.\n",
        "  - **`temperature=0.7`**: Adjusts the randomness in the response generation. Lower values like 0.7 make responses more focused and deterministic.\n",
        "- **`return tokenizer.decode(outputs[0], skip_special_tokens=True)`**: Decodes the generated tokens back into readable text, omitting special tokens."
      ],
      "metadata": {
        "id": "SUZ7r5Lo_7YB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP4SckCehlgQ"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, max_length=500):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1, temperature=0.7)\n",
        "\n",
        "    # Decode the generated response\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.**Processing Customer Feedback**\n",
        "\n",
        "This function processes customer feedback and generates a professional response based on the feedback's sentiment and content.\n",
        "\n",
        "- **`message`**: The customer's feedback.\n",
        "- **`category`**: The category of the feedback (e.g., Mobile Network, Mobile Package).\n",
        "- **`prompt`**: The structured prompt provided to the model to generate a response.\n",
        "- **`generate_response(prompt, max_length=500)`**: Generates a response using the AI model, with a maximum length of 500 tokens.\n",
        "- **`return response`**: Returns the generated customer service response based on the feedback."
      ],
      "metadata": {
        "id": "LMSF-YH4BG6A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxPmHx4hMFT"
      },
      "outputs": [],
      "source": [
        "def process_feedback(message, category):\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional customer service assistant for a telecom company. A customer has submitted the following feedback in the category of {category}:\n",
        "\n",
        "    \"{message}\"\n",
        "\n",
        "    Please respond with:\n",
        "    1. A clear identification of the sentiment (positive, negative, or neutral).\n",
        "    2. A concise, empathetic, and professional response addressing the customer's concern.\n",
        "    3. If appropriate, include a solution or next steps for the customer.\n",
        "\n",
        "    Format the output as:\n",
        "    Sentiment: [positive/negative/neutral]\n",
        "    Response: [Your customer response]\n",
        "\n",
        "    No extra information or format explanations should be included.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate response from the model\n",
        "    response = generate_response(prompt, max_length=500)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.**Chatbot with Error Handling and Feedback Storage**\n",
        "\n",
        "This function processes customer feedback, identifies any errors, and stores the feedback with its sentiment in a database.\n",
        "\n",
        "- **`message`**: The feedback text provided by the user.\n",
        "- **`category`**: The category related to the feedback (e.g., Mobile Network, Mosan Emoney).\n",
        "- **`process_feedback(message, category)`**: Processes the feedback based on its category using another function.\n",
        "- **`generate_response(prompt, max_length)`**: Generates an AI response with a limit on the number of tokens.\n",
        "- **`Session()`**: Creates a new session for database interaction.\n",
        "- **`Feedback`**: A model class representing the feedback table in the database.\n",
        "- **`session.add(feedback)`**: Adds the feedback to the database session.\n",
        "- **`session.commit()`**: Saves the feedback to the database.\n",
        "- **Error Handling**: If an error occurs, the bot generates an apology response using the AI model."
      ],
      "metadata": {
        "id": "NxRx0RtiBzRJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owl9SSe5hO69"
      },
      "outputs": [],
      "source": [
        "def chatbot(message, category):\n",
        "    if not message.strip():\n",
        "        return \"Error: Please provide feedback text.\"\n",
        "    if not category:\n",
        "        return \"Error: Please select a category.\"\n",
        "\n",
        "    try:\n",
        "        # Process the feedback with the category\n",
        "        result = process_feedback(message, category)\n",
        "\n",
        "        # Parse the result\n",
        "        lines = result.split('\\n')\n",
        "        parsed_result = {}\n",
        "        for line in lines:\n",
        "            if ':' in line:\n",
        "                key, value = line.split(':', 1)\n",
        "                parsed_result[key.strip()] = value.strip()\n",
        "\n",
        "        # Extract sentiment and response\n",
        "        sentiment = parsed_result.get('Sentiment', 'Unknown')\n",
        "        response = parsed_result.get('Response', '')\n",
        "\n",
        "        # If no response is generated, use a fallback\n",
        "        if not response:\n",
        "            fallback_prompt = f\"Provide a brief, helpful response to a customer's feedback about {category}: '{message}'\"\n",
        "            response = generate_response(fallback_prompt, max_length=150)\n",
        "\n",
        "        # Save the feedback to the database\n",
        "        session = Session()\n",
        "        feedback = Feedback(\n",
        "            category=category,\n",
        "            original_text=message,\n",
        "            sentiment=sentiment,\n",
        "            response=response\n",
        "        )\n",
        "        session.add(feedback)\n",
        "        session.commit()\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        error_prompt = f\"Briefly apologize and offer assistance for an error in processing feedback about {category}: '{message}'\"\n",
        "        error_response = generate_response(error_prompt, max_length=100)\n",
        "        return error_response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.**Gradio interface** for a telecommunication customer support chatbot.\n",
        "This function is allows users to select a feedback category, enter feedback, and submit it to receive a chatbot-generated response.\n",
        "\n",
        "1. **`gr.Blocks()`**: This defines the structure of the Gradio interface using block elements.\n",
        "   \n",
        "2. **`gr.Markdown(\"# Telecommunication Customer Support Chatbot\")`**: Displays a title for the chatbot interface.\n",
        "\n",
        "3. **`category = gr.Dropdown(...)`**: Creates a dropdown for the user to select the feedback category. The options are defined by the `CATEGORIES` list (not shown here).\n",
        "\n",
        "4. **`message = gr.Textbox(...)`**: Provides a textbox for users to input their feedback. It allows for multi-line input (3 lines) and includes a placeholder text for guidance.\n",
        "\n",
        "5. **`output = gr.TextArea(...)`**: A large text area where the chatbot's response will be displayed, with enough space (10 lines) to handle longer replies.\n",
        "\n",
        "6. **`submit_btn = gr.Button(\"Submit Feedback\")`**: Adds a button labeled \"Submit Feedback\" for users to send their input.\n",
        "\n",
        "7. **`submit_btn.click(...)`**: Connects the button to the `chatbot` function. When clicked, it sends the feedback (`message`) and selected `category` as inputs, and displays the output in the `output` TextArea.\n",
        "\n",
        "8. **`gr.Examples(...)`**: Displays preset feedback examples with categories and messages. Users can click these examples to autofill the input fields for demonstration purposes.\n",
        "\n"
      ],
      "metadata": {
        "id": "wxrmlC-ZCjL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG98Mdt0dyj4"
      },
      "outputs": [],
      "source": [
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Telecommunication Customer Support Chatbot\")\n",
        "\n",
        "    category = gr.Dropdown(choices=CATEGORIES, label=\"Select Feedback Category\")\n",
        "    message = gr.Textbox(lines=3, placeholder=\"Type your feedback here...\", label=\"Your Feedback\")\n",
        "\n",
        "    # Use TextArea for better long-text handling\n",
        "    output = gr.TextArea(label=\"Chatbot Response\", lines=10)\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit Feedback\")\n",
        "    submit_btn.click(fn=chatbot, inputs=[message, category], outputs=output)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"Mobile Network\", \"The network is down in my area for days.\"],\n",
        "            [\"Mobile Package\", \"I'm happy with the new data package!\"],\n",
        "            [\"Mosan Emoney\", \"I have an issue with my last Mosan Emoney transfer.\"],\n",
        "            [\"Recharge\", \"I need help with my recent recharge transaction.\"]\n",
        "        ],\n",
        "        inputs=[category, message]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Start and display the Gradio interface.**\n",
        "\n",
        "- **`demo.launch()`**: This method launches the Gradio app, making it interactive. Once called, it opens the interface in a browser or displays a link (if running in a cloud environment like Google Colab) that allows users to interact with the chatbot."
      ],
      "metadata": {
        "id": "_xViZkwAC4fk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLZGUw3geE5D"
      },
      "outputs": [],
      "source": [
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.**Visualizes customer sentiment trends**\n",
        "\n",
        "This function plots the distribution of sentiments (positive, negative, neutral) across different feedback categories based on data from the database.\n",
        "\n",
        "1. **Database Query**:\n",
        "   - It queries the database to retrieve all the feedback using `session.query(Feedback).all()`.\n",
        "   - The session is then closed to release the connection to the database.\n",
        "\n",
        "2. **Data Processing**:\n",
        "   - It uses a dictionary `category_sentiment_count` to store the count of each sentiment per feedback category.\n",
        "   - Sentiment values are converted to lowercase to ensure consistency when comparing.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "3. **Prepare Data for Plotting**:\n",
        "   - `categories`: List of all feedback categories.\n",
        "   - For each category, it counts the number of positive, negative, and neutral feedbacks.\n",
        "\n",
        "4. **Plotting**:\n",
        "   - The function uses `matplotlib` to create a bar plot with three sets of bars: one for each sentiment (positive, negative, neutral).\n",
        "   - `bar_width` controls the width of each bar, and the x-positions of the bars are adjusted so they don't overlap.\n",
        "   - It customizes the plot with labels for the x-axis (feedback categories), y-axis (number of feedback), and a title.\n",
        "\n",
        "5. **Saving the Plot**:\n",
        "   - The plot is saved as an image file named `sentiment_distribution.png` using `plt.savefig()`.\n",
        "   - The plot is then closed to avoid display issues, especially in environments where multiple plots are generated.\n",
        "\n",
        "6. **Return**:\n",
        "   - The function returns the path to the saved image file, which can be displayed in a Gradio interface.\n"
      ],
      "metadata": {
        "id": "HKmlX9sqDgsu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7JdjR-HwiNq"
      },
      "outputs": [],
      "source": [
        "# Function to plot the data\n",
        "def plot_sentiment_distribution():\n",
        "    # Query the database to retrieve the feedback data\n",
        "    session = Session()\n",
        "    feedback_data = session.query(Feedback).all()\n",
        "\n",
        "    # Processing data: count sentiments per category\n",
        "    category_sentiment_count = {}\n",
        "\n",
        "    for feedback in feedback_data:\n",
        "        category = feedback.category\n",
        "        sentiment = feedback.sentiment.lower()  # Convert sentiment to lowercase for consistency\n",
        "\n",
        "        if category not in category_sentiment_count:\n",
        "            category_sentiment_count[category] = Counter()\n",
        "\n",
        "        category_sentiment_count[category][sentiment] += 1\n",
        "\n",
        "    session.close()\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    categories = list(category_sentiment_count.keys())\n",
        "    positive_counts = [category_sentiment_count[cat].get('positive', 0) for cat in categories]\n",
        "    negative_counts = [category_sentiment_count[cat].get('negative', 0) for cat in categories]\n",
        "    neutral_counts = [category_sentiment_count[cat].get('neutral', 0) for cat in categories]\n",
        "\n",
        "    # Plotting the data with adjusted bar width and position\n",
        "    x = range(len(categories))  # x-coordinates\n",
        "    bar_width = 0.2  # Adjust the bar width\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plotting positive, negative, and neutral sentiment bars for each category\n",
        "    plt.bar([i - bar_width for i in x], positive_counts, width=bar_width, label='Positive', align='center')\n",
        "    plt.bar(x, negative_counts, width=bar_width, label='Negative', align='center')\n",
        "    plt.bar([i + bar_width for i in x], neutral_counts, width=bar_width, label='Neutral', align='center')\n",
        "\n",
        "    # Customizing the plot\n",
        "    plt.xlabel('Feedback Categories')\n",
        "    plt.ylabel('Number of Feedback')\n",
        "    plt.title('Sentiment Distribution by Feedback Categories')\n",
        "    plt.xticks(x, categories, rotation=45)\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot as an image\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sentiment_distribution.png')  # Save the plot as an image\n",
        "    plt.close()  # Close the plot to avoid display issues\n",
        "\n",
        "    # Return the image path for Gradio to display\n",
        "    return 'sentiment_distribution.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradio Interface for customer sentiment trends**\n",
        "Interface will display the sentiment distribution plot for telecom customer feedback data without requiring any user input.\n",
        "\n",
        "1. **`interface = gr.Interface(...)`**: This creates a Gradio interface for displaying the sentiment distribution plot generated by the `plot_sentiment_distribution` function.\n",
        "\n",
        "2. **`fn=plot_sentiment_distribution`**: Specifies that the `plot_sentiment_distribution` function is the core function executed when the interface is run.\n",
        "\n",
        "3. **`inputs=[]`**: No inputs are required from the user since the function retrieves and processes the data directly from the database.\n",
        "\n",
        "4. **`outputs=\"image\"`**: The output of the function is an image (the saved plot) which will be displayed in the interface.\n",
        "\n",
        "5. **`title=\"Telecom Support Feedback Sentiment\"`**: This is the title that appears at the top of the Gradio interface.\n",
        "\n"
      ],
      "metadata": {
        "id": "8fyEjtcBEBse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio interface\n",
        "interface = gr.Interface(fn=plot_sentiment_distribution, inputs=[], outputs=\"image\", title=\"Telecom Support Feedback Sentiment\")"
      ],
      "metadata": {
        "id": "fTQYsMyHAuNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Start and display the Gradio interface.\n",
        "\n",
        "- **`interface.launch()`**: This starts the Gradio application, opening a browser window or providing a link to the interface if it's running in a cloud environment. The interface will display the sentiment distribution plot image generated by the `plot_sentiment_distribution` function."
      ],
      "metadata": {
        "id": "lIbKL84rEvtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "rPl0lrh6AvH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **About the Author**\n",
        "\n",
        "**Ajito Nelson** is a passionate **Big Data Engineer** and **AI Enthusiast**. With a deep interest in data-driven solutions and artificial intelligence, Ajito is dedicated to leveraging cutting-edge technology to solve complex challenges. His expertise spans across big data infrastructure, machine learning, and AI applications in various domains.\n",
        "\n",
        "You can connect with me on [LinkedIn](https://www.linkedin.com/in/ajitonelson/).\n",
        "\n",
        "![Aji To Nelson](https://media.licdn.com/dms/image/v2/C5603AQENYxgypX_VSg/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1659079610353?e=1732752000&v=beta&t=H5SDXNRWwwIviJ1lP8muSj9Xb2Aa0rCklbaZ0Hgjnf8)"
      ],
      "metadata": {
        "id": "A_roNYYyGZGc"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}