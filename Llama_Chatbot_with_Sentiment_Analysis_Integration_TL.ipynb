{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajitonelsonn/TELE_Feedback/blob/main/Llama_Chatbot_with_Sentiment_Analysis_Integration_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TELE Feedback**\n",
        "\n",
        "TELE Feedback is an AI-powered chatbot designed for a telecommunications company in Timor-Leste. It allows customers to provide feedback while integrating sentiment analysis to assess the tone of their messages. The project includes a simple interface for interaction and visualization of sentiment trends."
      ],
      "metadata": {
        "id": "ff9PKaHr1vj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Installing Required Libraries**\n",
        "\n",
        "This cell installs all the libraries that the project depends on. These libraries are necessary for different functionalities like interacting with the Hugging Face models, creating a web interface for the chatbot, handling database operations, and visualizing feedback data.\n",
        "\n",
        "- **`huggingface_hub`**: Allows the project to access pre-trained models from Hugging Face's model hub.\n",
        "- **`gradio`**: Used to create an interactive web interface for the chatbot where users can input text and get responses.\n",
        "- **`transformers`**: A library from Hugging Face that provides tools to use pre-trained models for natural language processing tasks, like language generation and sentiment analysis.\n",
        "- **`sqlalchemy`**: An SQL toolkit for Python that helps in managing the storage and retrieval of data in a database.\n",
        "- **`pandas`**: Used for data manipulation and analysis.\n",
        "- **`matplotlib`**: A popular plotting library used for visualizing data, such as feedback trends.\n",
        "- **`torch`**: PyTorch is a framework used for loading and running machine learning models."
      ],
      "metadata": {
        "id": "LbTx0nin4AGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsivCpEll_Ig"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub gradio git+https://github.com/huggingface/transformers sqlalchemy pandas matplotlib torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Importing Necessary Libraries**\n",
        "\n",
        "This cell imports all the necessary libraries and modules required throughout the project.\n",
        "\n",
        "- **`huggingface_hub.login`**: Used to log in to Hugging Face, so you can access models stored in your account or publicly available models.\n",
        "- **`gradio`**: Used for creating a user interface where people can interact with your chatbot.\n",
        "- **`transformers.AutoModelForCausalLM` and `AutoTokenizer`**: These two classes load a pre-trained language model and its tokenizer, which are essential for generating chatbot responses.\n",
        "- **SQLAlchemy-related imports**:\n",
        "  - **`create_engine`**: Connects the code to the SQLite database.\n",
        "  - **`Column`, `Integer`, `String`**: These are data types used to define the database schema.\n",
        "  - **`declarative_base`**: A base class used to define the database table structure.\n",
        "  - **`sessionmaker`**: Creates sessions to interact with the database.\n",
        "- **`torch`**: PyTorch framework, required to load and run machine learning models like the chatbot.\n",
        "- **`matplotlib.pyplot`**: This is used to plot graphs or charts, such as visualizing feedback data trends.\n",
        "- **`collections.Counter`**: This utility helps in counting the occurrences of feedback sentiments (positive, negative, neutral)."
      ],
      "metadata": {
        "id": "NBJjzFuM4Lnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG6vgKlwd1Fi"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sqlalchemy import create_engine, Column, Integer, String\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Hugging Face Login**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Hugging Face login (you need to provide your token)\n",
        "login(token=\"your_huggingface_token_here\")\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This cell is responsible for logging into Hugging Face using your personal API token. If you don’t log in, you won’t be able to access models that are either private or require authentication.\n",
        "\n",
        "- **`login(token=\"your_huggingface_token_here\")`**: Replace `\"your_huggingface_token_here\"` with your actual token from Hugging Face. This allows the script to access models and datasets from the Hugging Face platform.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sE8_y9Ke4e2e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc4IIR8Sd2xL"
      },
      "outputs": [],
      "source": [
        "# Hugging Face login (you need to provide your token)\n",
        "login(token=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. **Loading the Pre-Trained Model and Tokenizer**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Load pre-trained model and tokenizer from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"model_name\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"model_name\")\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This cell loads the language model and tokenizer that will be used to generate chatbot responses.\n",
        "\n",
        "- **`AutoTokenizer.from_pretrained(\"model_name\")`**: This loads a tokenizer from Hugging Face. The tokenizer processes raw text input and converts it into tokens that the model can understand.\n",
        "- **`AutoModelForCausalLM.from_pretrained(\"model_name\")`**: This loads the pre-trained language model. A causal language model (like GPT) is capable of generating text responses based on the input tokens.\n",
        "\n",
        "The `model_name` should be replaced with the actual name of the pre-trained model you are using (for example, \"gpt-3\", \"gpt-2\", etc.)."
      ],
      "metadata": {
        "id": "KMPEd83J4_CV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. **Creating the Chatbot Function**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "def chatbot(input_text):\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs[\"input_ids\"])\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This function is the core of the chatbot logic. It takes user input, generates a response, and returns it.\n",
        "\n",
        "- **`input_text`**: The input text that the user provides.\n",
        "- **`tokenizer(input_text, return_tensors=\"pt\")`**: Tokenizes the user input and converts it into a tensor format required by the model.\n",
        "- **`model.generate(inputs[\"input_ids\"])`**: The pre-trained model generates a response based on the input text tokens.\n",
        "- **`tokenizer.decode(outputs[0], skip_special_tokens=True)`**: Converts the output tokens from the model back into human-readable text, skipping any special tokens like `<pad>` or `<eos>`.\n",
        "- **`return response`**: The chatbot returns the generated response.\n"
      ],
      "metadata": {
        "id": "6hd8sZbC5NS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. **Creating the Gradio Interface for the Chatbot**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Create Gradio interface for the chatbot\n",
        "interface = gr.Interface(fn=chatbot, inputs=\"text\", outputs=\"text\")\n",
        "interface.launch()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This cell creates and launches a Gradio interface where users can interact with the chatbot.\n",
        "\n",
        "- **`gr.Interface()`**: This creates a simple web interface where users can input text and get a response. It takes three arguments:\n",
        "  - **`fn=chatbot`**: Specifies the function (chatbot) to be executed when the user provides input.\n",
        "  - **`inputs=\"text\"`**: Specifies the input type for the interface, which is text in this case.\n",
        "  - **`outputs=\"text\"`**: Specifies the output type, which will be a text response.\n",
        "- **`interface.launch()`**: This launches the web interface, making it accessible in a web browser where users can start chatting with the bot."
      ],
      "metadata": {
        "id": "jWUOlXs75TQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. **Loading Sentiment Analysis Pipeline**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This cell loads a pre-trained sentiment analysis model from Hugging Face, which will be used to analyze the sentiment of user input.\n",
        "\n",
        "- **`pipeline(\"sentiment-analysis\")`**: This creates a sentiment analysis pipeline. The pipeline will classify text as **positive**, **neutral**, or **negative** based on its content. The model used here is a pre-trained one provided by Hugging Face."
      ],
      "metadata": {
        "id": "FRadEA2w5boL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. **Creating the Chatbot with Sentiment Analysis Function**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "def chatbot_with_sentiment(input_text):\n",
        "    # Get chatbot response\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs[\"input_ids\"])\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    # Analyze sentiment of user input\n",
        "    sentiment = sentiment_analyzer(input_text)\n",
        "    return response, sentiment\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This function generates both a chatbot response and performs sentiment analysis on the user’s input.\n",
        "\n",
        "- **`tokenizer(input_text, return_tensors=\"pt\")`** and **`model.generate()`**: The same steps as the `chatbot()` function to generate the chatbot response.\n",
        "- **`sentiment_analyzer(input_text)`**: The sentiment analysis model analyzes the user's input and returns whether the input was positive, negative, or neutral.\n",
        "- **`return response, sentiment`**: The function returns both the chatbot's response and the sentiment analysis result."
      ],
      "metadata": {
        "id": "4domGdux5hmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. **Creating Gradio Interface for Chatbot with Sentiment Analysis**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Create Gradio interface for the chatbot with sentiment analysis\n",
        "interface = gr.Interface(fn=chatbot_with_sentiment, inputs=\"text\", outputs=[\"text\", \"label\"])\n",
        "interface.launch()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This creates a Gradio interface that not only generates a chatbot response but also shows the sentiment of the user's input.\n",
        "\n",
        "- **`fn=chatbot_with_sentiment`**: The function to be executed is `chatbot_with_sentiment`, which returns both a chatbot response and sentiment analysis.\n",
        "- **`inputs=\"text\"`**: The input type is text.\n",
        "- **`outputs=[\"text\", \"label\"]`**: The output has two parts:\n",
        "  - **Text**: The chatbot's response.\n",
        "  - **Label**: The sentiment analysis result (positive, negative, or neutral).\n",
        "- **`interface.launch()`**: This launches the web interface."
      ],
      "metadata": {
        "id": "pKLGBZ7g5mLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. **Defining the SQLAlchemy Model for Feedback**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Define the SQLAlchemy model for storing feedback\n",
        "Base = declarative_base()\n",
        "\n",
        "class Feedback(Base):\n",
        "    __tablename__ = 'feedback\n",
        "\n",
        "'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    user_input = Column(String)\n",
        "    chatbot_response = Column(String)\n",
        "    sentiment = Column(String)\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This cell defines a **SQLAlchemy** model to store feedback data from the chatbot interaction. The data includes the user’s input, the chatbot’s response, and the sentiment of the user’s input.\n",
        "\n",
        "- **`Base = declarative_base()`**: Sets up a base class from which all database models (tables) will inherit.\n",
        "- **`Feedback` class**: Defines a table named `feedback` with columns:\n",
        "  - **`id`**: The primary key, a unique integer identifier for each row.\n",
        "  - **`user_input`**: Stores the user’s input.\n",
        "  - **`chatbot_response`**: Stores the chatbot’s generated response.\n",
        "  - **`sentiment`**: Stores the sentiment (positive, negative, or neutral) of the user’s input."
      ],
      "metadata": {
        "id": "iiBcoSlX5p8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. **Connecting to the SQLite Database**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Connect to the SQLite database\n",
        "engine = create_engine('sqlite:///feedback.db')\n",
        "Base.metadata.create_all(engine)\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This sets up the connection to an SQLite database called `feedback.db`.\n",
        "\n",
        "- **`create_engine('sqlite:///feedback.db')`**: Creates a connection to a SQLite database file named `feedback.db`. If it doesn’t exist, it will be created.\n",
        "- **`Base.metadata.create_all(engine)`**: Creates all the tables defined by the model (in this case, the `Feedback` table) in the database.\n",
        "- **`sessionmaker(bind=engine)`**: Creates a session factory bound to the database engine, which allows interactions with the database.\n",
        "- **`session = Session()`**: This is the session object used to execute transactions with the database (e.g., inserting or retrieving feedback data)."
      ],
      "metadata": {
        "id": "gcvMQQRt5t9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##12. **Function to Save Feedback in the Database**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "# Function to save feedback to the database\n",
        "def save_feedback(user_input, chatbot_response, sentiment):\n",
        "    new_feedback = Feedback(user_input=user_input, chatbot_response=chatbot_response, sentiment=sentiment)\n",
        "    session.add(new_feedback)\n",
        "    session.commit()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This function is responsible for saving the feedback data (user input, chatbot response, sentiment) into the database.\n",
        "\n",
        "- **`save_feedback()`**: This function takes three arguments:\n",
        "  - **`user_input`**: The user's input text.\n",
        "  - **`chatbot_response`**: The chatbot's response to the input.\n",
        "  - **`sentiment`**: The sentiment of the user's input.\n",
        "- **`new_feedback = Feedback(...)`**: Creates a new entry (row) in the `Feedback` table with the provided data.\n",
        "- **`session.add(new_feedback)`**: Adds the new entry to the session.\n",
        "- **`session.commit()`**: Commits the transaction, saving the new feedback entry into the database.\n"
      ],
      "metadata": {
        "id": "dVYTXFDE52pU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. **Gradio Interface for Displaying Data**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to retrieve and show feedback data\n",
        "def show_feedback():\n",
        "    feedback_data = session.query(Feedback).all()\n",
        "    feedback_dict = {\"User Input\": [fb.user_input for fb in feedback_data],\n",
        "                     \"Chatbot Response\": [fb.chatbot_response for fb in feedback_data],\n",
        "                     \"Sentiment\": [fb.sentiment for fb in feedback_data]}\n",
        "    return pd.DataFrame(feedback_dict)\n",
        "\n",
        "# Create Gradio interface to show feedback\n",
        "data_interface = gr.Interface(fn=show_feedback, inputs=None, outputs=\"dataframe\")\n",
        "data_interface.launch()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This part of the code creates a new Gradio interface that displays stored feedback data from the database in a table format.\n",
        "\n",
        "- **`show_feedback()`**:\n",
        "  - This function retrieves all feedback entries from the `Feedback` table.\n",
        "  - The feedback entries are converted into a dictionary format that contains lists of user input, chatbot responses, and sentiments.\n",
        "  - The dictionary is converted into a Pandas DataFrame, which is a tabular structure that Gradio can display.\n",
        "  \n",
        "- **`gr.Interface(fn=show_feedback, inputs=None, outputs=\"dataframe\")`**: Creates a Gradio interface for displaying the feedback data as a table. No user input is needed, and the output is a DataFrame (a table of data).\n",
        "\n",
        "- **`data_interface.launch()`**: Launches the web interface to display feedback data."
      ],
      "metadata": {
        "id": "k3WhwZ7458uA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 14. **Plotting Feedback Sentiment Trends**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "def plot_sentiment_trends():\n",
        "    feedback_data = session.query(Feedback).all()\n",
        "    sentiments = [fb.sentiment for fb in feedback_data]\n",
        "    sentiment_counts = Counter(sentiments)\n",
        "    \n",
        "    # Plot the sentiment counts\n",
        "    plt.bar(sentiment_counts.keys(), sentiment_counts.values())\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('Sentiment Distribution')\n",
        "    plt.show()\n",
        "\n",
        "# Create Gradio interface to show sentiment trends\n",
        "plot_interface = gr.Interface(fn=plot_sentiment_trends, inputs=None, outputs=\"plot\")\n",
        "plot_interface.launch()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This part creates a visualization of the sentiment trends from the feedback data.\n",
        "\n",
        "- **`plot_sentiment_trends()`**:\n",
        "  - Retrieves the sentiment data from all feedback entries.\n",
        "  - Counts the occurrences of each sentiment (positive, negative, neutral) using `Counter`.\n",
        "  - Plots a bar chart showing the distribution of sentiments.\n",
        "\n",
        "- **`plt.bar()`**: Creates a bar chart with sentiment categories on the x-axis and their counts on the y-axis.\n",
        "- **`gr.Interface(fn=plot_sentiment_trends, inputs=None, outputs=\"plot\")`**: Creates a Gradio interface that displays a plot. No input is required, and the output is a plot.\n",
        "- **`plot_interface.launch()`**: Launches the interface so users can see the sentiment trends.\n",
        "\n",
        "---\n",
        "\n",
        "## 15. **Saving Feedback after Each Chat**\n",
        "\n",
        "#### Code:\n",
        "```python\n",
        "def chatbot_with_sentiment_and_save(input_text):\n",
        "    # Get chatbot response\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs[\"input_ids\"])\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    # Analyze sentiment\n",
        "    sentiment = sentiment_analyzer(input_text)\n",
        "    \n",
        "    # Save feedback to the database\n",
        "    save_feedback(user_input=input_text, chatbot_response=response, sentiment=sentiment[0]['label'])\n",
        "    \n",
        "    return response, sentiment[0]['label']\n",
        "\n",
        "# Gradio interface for chatbot with sentiment analysis and feedback saving\n",
        "interface = gr.Interface(fn=chatbot_with_sentiment_and_save, inputs=\"text\", outputs=[\"text\", \"label\"])\n",
        "interface.launch()\n",
        "```\n",
        "\n",
        "#### Explanation:\n",
        "This final part integrates everything: chatbot functionality, sentiment analysis, and saving feedback.\n",
        "\n",
        "- **`chatbot_with_sentiment_and_save()`**:\n",
        "  - Generates a chatbot response.\n",
        "  - Analyzes the sentiment of the user’s input.\n",
        "  - Saves the user input, chatbot response, and sentiment into the database by calling `save_feedback()`.\n",
        "  \n",
        "- **`gr.Interface()`**: Creates a Gradio interface that handles chatbot interactions, sentiment analysis, and automatically saves the feedback.\n",
        "  \n",
        "- **`interface.launch()`**: Launches the chatbot interface where users can interact and have their feedback stored."
      ],
      "metadata": {
        "id": "JTmFzoQS3zXp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ4HbQDyd4QF"
      },
      "outputs": [],
      "source": [
        "# Database setup\n",
        "Base = declarative_base()\n",
        "engine = create_engine('sqlite:///telecom_support.db', echo=False)\n",
        "Session = sessionmaker(bind=engine)\n",
        "\n",
        "class Feedback(Base):\n",
        "    __tablename__ = 'feedback'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    category = Column(String)\n",
        "    original_text = Column(String)\n",
        "    sentiment = Column(String)\n",
        "    response = Column(String)\n",
        "\n",
        "Base.metadata.create_all(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir35KJLOd_zD"
      },
      "outputs": [],
      "source": [
        "# Load Llama 2 model\n",
        "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPxNmYMaeBUJ"
      },
      "outputs": [],
      "source": [
        "# Updated categories for a telecom company\n",
        "CATEGORIES = [\"Mobile Network\", \"Mobile Package\", \"Mosan Emoney\", \"Recharge\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP4SckCehlgQ"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, max_length=500):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1, temperature=0.7)\n",
        "\n",
        "    # Decode the generated response\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxPmHx4hMFT"
      },
      "outputs": [],
      "source": [
        "def process_feedback(message, category):\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional customer service assistant for a telecom company. A customer has submitted the following feedback in the category of {category}:\n",
        "\n",
        "    \"{message}\"\n",
        "\n",
        "    Please respond with:\n",
        "    1. A clear identification of the sentiment (positive, negative, or neutral).\n",
        "    2. A concise, empathetic, and professional response addressing the customer's concern.\n",
        "    3. If appropriate, include a solution or next steps for the customer.\n",
        "\n",
        "    Format the output as:\n",
        "    Sentiment: [positive/negative/neutral]\n",
        "    Response: [Your customer response]\n",
        "\n",
        "    No extra information or format explanations should be included.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate response from the model\n",
        "    response = generate_response(prompt, max_length=500)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owl9SSe5hO69"
      },
      "outputs": [],
      "source": [
        "def chatbot(message, category):\n",
        "    if not message.strip():\n",
        "        return \"Error: Please provide feedback text.\"\n",
        "    if not category:\n",
        "        return \"Error: Please select a category.\"\n",
        "\n",
        "    try:\n",
        "        # Process the feedback with the category\n",
        "        result = process_feedback(message, category)\n",
        "\n",
        "        # Parse the result\n",
        "        lines = result.split('\\n')\n",
        "        parsed_result = {}\n",
        "        for line in lines:\n",
        "            if ':' in line:\n",
        "                key, value = line.split(':', 1)\n",
        "                parsed_result[key.strip()] = value.strip()\n",
        "\n",
        "        # Extract sentiment and response\n",
        "        sentiment = parsed_result.get('Sentiment', 'Unknown')\n",
        "        response = parsed_result.get('Response', '')\n",
        "\n",
        "        # If no response is generated, use a fallback\n",
        "        if not response:\n",
        "            fallback_prompt = f\"Provide a brief, helpful response to a customer's feedback about {category}: '{message}'\"\n",
        "            response = generate_response(fallback_prompt, max_length=150)\n",
        "\n",
        "        # Save the feedback to the database\n",
        "        session = Session()\n",
        "        feedback = Feedback(\n",
        "            category=category,\n",
        "            original_text=message,\n",
        "            sentiment=sentiment,\n",
        "            response=response\n",
        "        )\n",
        "        session.add(feedback)\n",
        "        session.commit()\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        error_prompt = f\"Briefly apologize and offer assistance for an error in processing feedback about {category}: '{message}'\"\n",
        "        error_response = generate_response(error_prompt, max_length=100)\n",
        "        return error_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG98Mdt0dyj4"
      },
      "outputs": [],
      "source": [
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Telecommunication Customer Support Chatbot\")\n",
        "\n",
        "    category = gr.Dropdown(choices=CATEGORIES, label=\"Select Feedback Category\")\n",
        "    message = gr.Textbox(lines=3, placeholder=\"Type your feedback here...\", label=\"Your Feedback\")\n",
        "\n",
        "    # Use TextArea for better long-text handling\n",
        "    output = gr.TextArea(label=\"Chatbot Response\", lines=10)\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit Feedback\")\n",
        "    submit_btn.click(fn=chatbot, inputs=[message, category], outputs=output)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"Mobile Network\", \"The network is down in my area for days.\"],\n",
        "            [\"Mobile Package\", \"I'm happy with the new data package!\"],\n",
        "            [\"Mosan Emoney\", \"I have an issue with my last Mosan Emoney transfer.\"],\n",
        "            [\"Recharge\", \"I need help with my recent recharge transaction.\"]\n",
        "        ],\n",
        "        inputs=[category, message]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLZGUw3geE5D"
      },
      "outputs": [],
      "source": [
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7JdjR-HwiNq"
      },
      "outputs": [],
      "source": [
        "# Function to plot the data\n",
        "def plot_sentiment_distribution():\n",
        "    # Query the database to retrieve the feedback data\n",
        "    session = Session()\n",
        "    feedback_data = session.query(Feedback).all()\n",
        "\n",
        "    # Processing data: count sentiments per category\n",
        "    category_sentiment_count = {}\n",
        "\n",
        "    for feedback in feedback_data:\n",
        "        category = feedback.category\n",
        "        sentiment = feedback.sentiment.lower()  # Convert sentiment to lowercase for consistency\n",
        "\n",
        "        if category not in category_sentiment_count:\n",
        "            category_sentiment_count[category] = Counter()\n",
        "\n",
        "        category_sentiment_count[category][sentiment] += 1\n",
        "\n",
        "    session.close()\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    categories = list(category_sentiment_count.keys())\n",
        "    positive_counts = [category_sentiment_count[cat].get('positive', 0) for cat in categories]\n",
        "    negative_counts = [category_sentiment_count[cat].get('negative', 0) for cat in categories]\n",
        "    neutral_counts = [category_sentiment_count[cat].get('neutral', 0) for cat in categories]\n",
        "\n",
        "    # Plotting the data with adjusted bar width and position\n",
        "    x = range(len(categories))  # x-coordinates\n",
        "    bar_width = 0.2  # Adjust the bar width\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plotting positive, negative, and neutral sentiment bars for each category\n",
        "    plt.bar([i - bar_width for i in x], positive_counts, width=bar_width, label='Positive', align='center')\n",
        "    plt.bar(x, negative_counts, width=bar_width, label='Negative', align='center')\n",
        "    plt.bar([i + bar_width for i in x], neutral_counts, width=bar_width, label='Neutral', align='center')\n",
        "\n",
        "    # Customizing the plot\n",
        "    plt.xlabel('Feedback Categories')\n",
        "    plt.ylabel('Number of Feedback')\n",
        "    plt.title('Sentiment Distribution by Feedback Categories')\n",
        "    plt.xticks(x, categories, rotation=45)\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot as an image\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sentiment_distribution.png')  # Save the plot as an image\n",
        "    plt.close()  # Close the plot to avoid display issues\n",
        "\n",
        "    # Return the image path for Gradio to display\n",
        "    return 'sentiment_distribution.png'\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(fn=plot_sentiment_distribution, inputs=[], outputs=\"image\", title=\"Telecom Support Feedback Sentiment\")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}