{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajitonelsonn/TELE_Feedback/blob/main/Llama_Chatbot_with_Sentiment_Analysis_Integration_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TELE Feedback**"
      ],
      "metadata": {
        "id": "ff9PKaHr1vj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsivCpEll_Ig"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub gradio git+https://github.com/huggingface/transformers sqlalchemy pandas matplotlib torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG6vgKlwd1Fi"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sqlalchemy import create_engine, Column, Integer, String\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy import Column, Integer, String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc4IIR8Sd2xL"
      },
      "outputs": [],
      "source": [
        "# Hugging Face login (you need to provide your token)\n",
        "login(token=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ4HbQDyd4QF"
      },
      "outputs": [],
      "source": [
        "# Database setup\n",
        "Base = declarative_base()\n",
        "engine = create_engine('sqlite:///telecom_support.db', echo=False)\n",
        "Session = sessionmaker(bind=engine)\n",
        "\n",
        "class Feedback(Base):\n",
        "    __tablename__ = 'feedback'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    category = Column(String)\n",
        "    original_text = Column(String)\n",
        "    sentiment = Column(String)\n",
        "    response = Column(String)\n",
        "\n",
        "Base.metadata.create_all(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir35KJLOd_zD"
      },
      "outputs": [],
      "source": [
        "# Load Llama 2 model\n",
        "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPxNmYMaeBUJ"
      },
      "outputs": [],
      "source": [
        "# Updated categories for a telecom company\n",
        "CATEGORIES = [\"Mobile Network\", \"Mobile Package\", \"Mosan Emoney\", \"Recharge\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP4SckCehlgQ"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, max_length=500):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1, temperature=0.7)\n",
        "\n",
        "    # Decode the generated response\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxPmHx4hMFT"
      },
      "outputs": [],
      "source": [
        "def process_feedback(message, category):\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional customer service assistant for a telecom company. A customer has submitted the following feedback in the category of {category}:\n",
        "\n",
        "    \"{message}\"\n",
        "\n",
        "    Please respond with:\n",
        "    1. A clear identification of the sentiment (positive, negative, or neutral).\n",
        "    2. A concise, empathetic, and professional response addressing the customer's concern.\n",
        "    3. If appropriate, include a solution or next steps for the customer.\n",
        "\n",
        "    Format the output as:\n",
        "    Sentiment: [positive/negative/neutral]\n",
        "    Response: [Your customer response]\n",
        "\n",
        "    No extra information or format explanations should be included.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate response from the model\n",
        "    response = generate_response(prompt, max_length=500)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owl9SSe5hO69"
      },
      "outputs": [],
      "source": [
        "def chatbot(message, category):\n",
        "    if not message.strip():\n",
        "        return \"Error: Please provide feedback text.\"\n",
        "    if not category:\n",
        "        return \"Error: Please select a category.\"\n",
        "\n",
        "    try:\n",
        "        # Process the feedback with the category\n",
        "        result = process_feedback(message, category)\n",
        "\n",
        "        # Parse the result\n",
        "        lines = result.split('\\n')\n",
        "        parsed_result = {}\n",
        "        for line in lines:\n",
        "            if ':' in line:\n",
        "                key, value = line.split(':', 1)\n",
        "                parsed_result[key.strip()] = value.strip()\n",
        "\n",
        "        # Extract sentiment and response\n",
        "        sentiment = parsed_result.get('Sentiment', 'Unknown')\n",
        "        response = parsed_result.get('Response', '')\n",
        "\n",
        "        # If no response is generated, use a fallback\n",
        "        if not response:\n",
        "            fallback_prompt = f\"Provide a brief, helpful response to a customer's feedback about {category}: '{message}'\"\n",
        "            response = generate_response(fallback_prompt, max_length=150)\n",
        "\n",
        "        # Save the feedback to the database\n",
        "        session = Session()\n",
        "        feedback = Feedback(\n",
        "            category=category,\n",
        "            original_text=message,\n",
        "            sentiment=sentiment,\n",
        "            response=response\n",
        "        )\n",
        "        session.add(feedback)\n",
        "        session.commit()\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        error_prompt = f\"Briefly apologize and offer assistance for an error in processing feedback about {category}: '{message}'\"\n",
        "        error_response = generate_response(error_prompt, max_length=100)\n",
        "        return error_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG98Mdt0dyj4"
      },
      "outputs": [],
      "source": [
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Telecommunication Customer Support Chatbot\")\n",
        "\n",
        "    category = gr.Dropdown(choices=CATEGORIES, label=\"Select Feedback Category\")\n",
        "    message = gr.Textbox(lines=3, placeholder=\"Type your feedback here...\", label=\"Your Feedback\")\n",
        "\n",
        "    # Use TextArea for better long-text handling\n",
        "    output = gr.TextArea(label=\"Chatbot Response\", lines=10)\n",
        "\n",
        "    submit_btn = gr.Button(\"Submit Feedback\")\n",
        "    submit_btn.click(fn=chatbot, inputs=[message, category], outputs=output)\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"Mobile Network\", \"The network is down in my area for days.\"],\n",
        "            [\"Mobile Package\", \"I'm happy with the new data package!\"],\n",
        "            [\"Mosan Emoney\", \"I have an issue with my last Mosan Emoney transfer.\"],\n",
        "            [\"Recharge\", \"I need help with my recent recharge transaction.\"]\n",
        "        ],\n",
        "        inputs=[category, message]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLZGUw3geE5D"
      },
      "outputs": [],
      "source": [
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7JdjR-HwiNq"
      },
      "outputs": [],
      "source": [
        "# Function to plot the data\n",
        "def plot_sentiment_distribution():\n",
        "    # Query the database to retrieve the feedback data\n",
        "    session = Session()\n",
        "    feedback_data = session.query(Feedback).all()\n",
        "\n",
        "    # Processing data: count sentiments per category\n",
        "    category_sentiment_count = {}\n",
        "\n",
        "    for feedback in feedback_data:\n",
        "        category = feedback.category\n",
        "        sentiment = feedback.sentiment.lower()  # Convert sentiment to lowercase for consistency\n",
        "\n",
        "        if category not in category_sentiment_count:\n",
        "            category_sentiment_count[category] = Counter()\n",
        "\n",
        "        category_sentiment_count[category][sentiment] += 1\n",
        "\n",
        "    session.close()\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    categories = list(category_sentiment_count.keys())\n",
        "    positive_counts = [category_sentiment_count[cat].get('positive', 0) for cat in categories]\n",
        "    negative_counts = [category_sentiment_count[cat].get('negative', 0) for cat in categories]\n",
        "    neutral_counts = [category_sentiment_count[cat].get('neutral', 0) for cat in categories]\n",
        "\n",
        "    # Plotting the data with adjusted bar width and position\n",
        "    x = range(len(categories))  # x-coordinates\n",
        "    bar_width = 0.2  # Adjust the bar width\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plotting positive, negative, and neutral sentiment bars for each category\n",
        "    plt.bar([i - bar_width for i in x], positive_counts, width=bar_width, label='Positive', align='center')\n",
        "    plt.bar(x, negative_counts, width=bar_width, label='Negative', align='center')\n",
        "    plt.bar([i + bar_width for i in x], neutral_counts, width=bar_width, label='Neutral', align='center')\n",
        "\n",
        "    # Customizing the plot\n",
        "    plt.xlabel('Feedback Categories')\n",
        "    plt.ylabel('Number of Feedback')\n",
        "    plt.title('Sentiment Distribution by Feedback Categories')\n",
        "    plt.xticks(x, categories, rotation=45)\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot as an image\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sentiment_distribution.png')  # Save the plot as an image\n",
        "    plt.close()  # Close the plot to avoid display issues\n",
        "\n",
        "    # Return the image path for Gradio to display\n",
        "    return 'sentiment_distribution.png'\n",
        "\n",
        "# Gradio interface\n",
        "interface = gr.Interface(fn=plot_sentiment_distribution, inputs=[], outputs=\"image\", title=\"Telecom Support Feedback Sentiment\")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}